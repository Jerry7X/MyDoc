## 价值说明

当前rgw的bi层是偏弱化的，主要是为了实现bucket list功能。数据的读请求仍然是直接到对象的。
这里有几个问题：
1，数据一致性，多版本一致性实现复杂。
   由于数据的读仍然以object为准，所以object上存储了对象的元数据，但是bucket list也需要展示部分元数据，
为了保证一致性，rgw使用了prepare/complete机制。但是多版本下该问题进一步复杂化，需要保证olh，object，bi entry的一致性。
设计上这里仍然存在一些一致性问题，参见#415。
   olh，null instance与olh混在一起，逻辑复杂。

2，不方便实现bucket跨pool，跨集群等特性，不利于对DataStorage层进行抽象。

   在当前框架下，实现bucket跨pool需要在原始pool保留一个logic head类似方案（https://etherpad.net/p/multiple-data-pool-support-for-a-bucket）。
   这种方案下data pool需要存储大量小文件（head对象的大小也不好配置，配置大了则data pool难以放下，小了则1MB文件可能涉及多次IO，影响性能）。

3，替换使用其他DB存储BI，以解决rados object恢复导致业务中断的问题

4, 读写流程的影响
   由于要直接通过object定位到对象，所以logic head成为必须，在对象覆盖写场景下，需要对其做特殊处理。写入流程复杂。
   
5，不方便实现文件去重
   文件去重，CDP等功能在logic head下实现复杂，同样需要考虑相关的一致性问题。
   
   
   
6, 小文件合并
   小文件合并必然引入索引层，索引层如果仍然使用logic head存，那根本没解决第一个data pool海量文件问题。
   内部使用多版本机制+ lc可以很方便的实现大文件的gc。


   

## 改造方案

rgw元数据以bi为准，所有请求先经过bi。

内部使用多版本机制实现一致性。

对象的属性信息也存放到BI中，以减少读的次数(否则既要读BI，还得读rados object属性)。
bucket/user等元数据存储策略暂时不变。

优化多版本的key管理，去掉olh相关逻辑，统一非多版本与多版本的管理

s3看到的对象
{name, instance}
bi存储对象
{
name,
[ {instance3, obj_name},
  {instance2, obj_name},
  {instance1, obj_name},
  {null, obj_name}
]
}

instance除了根据产生时间有序外，还提供了list key以支持marker方式排序。

针对上述问题：
1，一致性保证
   写入BI成功才算真的成功，raods object上不再保存元数据。多版本同样如此。
   如果写入rados对象成功，但是bi修改失败。则移除rados对象。一般来说不存在失败情况，除非bi相关的pool状态异常。
   （目前这里在失败的时候并未删除对象）

2，读写流程
   对于rados而言，每次都是写入新对象，直接顺序写即可，manifest也可以去掉，名字按照stripe计算。
   
3，在bi上增加实际存储的pool来支持bucket跨pool。
   修改原有的placement方案。placement就是存储策略，支持EC，多副本等。但是一个placement中只存在一种类型的
   的pool。还有一点就是要把data pool的状态管理起来，使用率，状态等等。
   
4，mtime等统一，bi的mtime为准

5，CDP可以基于去重以及COPY的思路实现。

## 关键设计

### BI数据结构

简化数据结构，去除不需要的字段

### 读写流程改造

   去掉head object，简化manifest。
   
  接口覆盖write_meta, delete_obj, get_object_state。
  
  删除rados object成功，再删除bi entry。
  
get的影响：
  get_object_state 不支持prefetch_data,仅读取某个instance元数据。
  
  get不指定instance即为获取最新的instance，get指定instance则获取对应的信息。
  指定instance时，可以指定null，null与empty是两种情况。null可能存在多个，但是读取的总是最近的一个。

### multipart的实现


### list实现
   current标记处理，list排序在object instance内的实现。

### 双活



双活这块也有影响，但是相对还好，主要是bilog的内容会做调整。同步不再关心olh。
每次同步都是一个object instance，object instance基于时间排序，在写入instance对时间做检查，
如果后写的对象时间比之前的小，说明时间有跳变，那么对时间进行修正。但是多站点之间时间不同步这里仍然有缺陷。


## 升级
可能考虑提供转换工具

### 性能分析

读性能会变差，目前的读可以一次性把属性和数据读取出来。
修改后读操作需要先读BI，然后读取数据。（可以考虑缓存属性）

写操作理论上会变好。bi操作可减少一次。

多版本读性能可能略下降，主要是bi的并发能力弱于object head。
多版本的写性能应该好不少，少了olh的一坨操作。（poc可增加该场景）

### 问题
1， acl等信息如何转化为json格式进行同步？
  attr在object instance中与之前一样的形式存储， get_obj_state的时候读取，对上层不感知。


## 残留对象
1，在写入对象成功，但是bi失败时，rgw提前退出，则对象会残留
2，对象数据部分写入成功，但是部分写入失败，这时没有清理残留数据。（之前也存在这种情况）
2，并发写入时，双方在get阶段均未发现对方写入的bi key，最终complete的时候，一方的bi key被覆盖，但是rados obj没有被清理。
